# ğŸ« AI-Powered Classroom Monitoring System

> **Kenya Science & Engineering Fair (KSEF) â€” Student Research Project**
> A simulation-based demonstration of real-time AI classroom monitoring for exam integrity, student behavior analysis, and engagement tracking.

---

## ğŸ… Project Overview

This project was developed and presented at the **Kenya Science and Engineering Fair (KSEF)** as a student research simulation. It explores the practical implementation of an **AI-powered classroom monitoring system** designed to:

- Enhance **exam integrity** by detecting potential misconduct in real time
- Analyse **student behavior** and classroom discipline
- Track **student engagement** using computer vision and machine learning

The web application serves as a working **proof-of-concept simulator**, demonstrating how AI technology can be applied to real-world educational environments â€” all running entirely within a modern web browser without any backend infrastructure.

---

## ğŸ“‹ Research Abstract

Traditional classroom monitoring relies heavily on human supervision, which is susceptible to **fatigue, human error, and oversight** â€” especially in large classrooms and examination settings. This research explores the use of **real-time object detection** (via TensorFlow.js and the COCO-SSD model) as a scalable alternative to manual monitoring.

The system simulates the detection of suspicious behaviors, tracks student attentiveness through visual cues, and measures classroom noise levels â€” providing educators with a unified analytical dashboard.

**The study concludes** that AI-based classroom monitoring is a promising tool for enhancing exam integrity and improving student behavior. Future research directions include scaling the system for larger institutions and incorporating **emotion recognition** to better assess student well-being and engagement.

---

## â— Problem Statement

Manual classroom supervision faces critical limitations:

| Challenge                    | Impact                                                     |
| ---------------------------- | ---------------------------------------------------------- |
| ğŸ‘ï¸ Human fatigue             | Reduced vigilance over long examination periods            |
| âš ï¸ Human error               | Subtle cheating behaviors and disengagement go undetected  |
| ğŸ“ Scale limitations         | Large classrooms make comprehensive monitoring impractical |
| ğŸ“Š No data trail             | Manual monitoring generates no analyzable behavioral data  |
| ğŸ˜´ Disengagement blind spots | Passive disengagement is difficult to observe and quantify |

This project demonstrates how AI can address each of these limitations with consistent, data-driven, real-time analysis.

---

## ğŸ’¡ Solution & Methodology

The system uses **in-browser machine learning** to simulate the monitoring pipeline:

1. **Video input** â€” live webcam stream or uploaded classroom video
2. **Object detection** â€” TensorFlow.js + COCO-SSD model detects persons in each frame
3. **Engagement scoring** â€” detection confidence scores are mapped to attention levels
4. **Noise monitoring** â€” Web Audio API measures real-time microphone amplitude as a proxy for classroom noise
5. **Dashboard analytics** â€” aggregated data is displayed via charts, stat cards, and a leaderboard

> ğŸ”¬ **Note:** This is a **simulation** built for the Science Fair. All dashboard statistics (engagement %, attendance, cheating alerts) are simulated to demonstrate the intended experience of a deployed system. The camera and video detection features use a real, live AI model (COCO-SSD).

---

## âœ¨ System Features

| Module                     | Description                                                                                                        |
| -------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| ğŸ“Š **Dashboard**           | Overview of engagement %, attendance %, and cheating incident alerts â€” auto-refreshes every 5 seconds              |
| ğŸ¥ **Live Camera Feed**    | Real-time webcam stream with AI bounding boxes, per-student attention scores, and live microphone noise monitoring |
| ğŸ“¡ **AI Video Processing** | Upload a recorded classroom video for frame-by-frame AI analysis with attention and noise meters                   |
| ğŸ“ˆ **Statistics**          | Bar and doughnut charts comparing class engagement and noise distribution; classroom leaderboard                   |
| âš™ï¸ **Settings**            | Configure AI sensitivity, alert threshold, and camera resolution (persisted via `localStorage`)                    |
| ğŸŒ™ **Dark Mode**           | System-wide dark mode toggle, persisted across page reloads                                                        |

---

## ğŸ—‚ï¸ Project Structure

```
classroomai/
â”œâ”€â”€ index.html          # Dashboard â€” engagement, attendance & cheating stats
â”œâ”€â”€ camerafeed.html     # Live webcam AI detection & noise monitoring
â”œâ”€â”€ livefeed.html       # Recorded video AI analysis with overlay
â”œâ”€â”€ statistics.html     # Charts & classroom leaderboard
â”œâ”€â”€ settings.html       # System configuration panel
â”œâ”€â”€ style.css           # Shared stylesheet â€” layout, sidebar, cards, dark mode
â”œâ”€â”€ livefeed.css        # Supplementary styles for the live feed page
â”œâ”€â”€ script.js           # Shared JS â€” dark mode, camera, AI model, stats simulation
â””â”€â”€ README.md           # Research documentation (this file)
```

---

## ğŸ› ï¸ Technology Stack

| Technology                    | Role                                                                                           |
| ----------------------------- | ---------------------------------------------------------------------------------------------- |
| **HTML5 / CSS3**              | Page structure and custom design system                                                        |
| **Vanilla JavaScript (ES6+)** | Application logic and AI integration                                                           |
| **Bootstrap 5**               | Responsive grid layout and UI components                                                       |
| **Font Awesome 6**            | Navigation and UI iconography                                                                  |
| **TensorFlow.js**             | In-browser machine learning runtime                                                            |
| **COCO-SSD**                  | Pre-trained object detection model (person detection)                                          |
| **Chart.js**                  | Statistical charts (bar & doughnut)                                                            |
| **Web APIs**                  | `getUserMedia` (camera/microphone), `AudioContext` (noise analysis), `localStorage` (settings) |

---

## ğŸ¤– AI Model Details

| Property              | Value                                                                |
| --------------------- | -------------------------------------------------------------------- |
| **Model**             | COCO-SSD (Common Objects in Context â€” Single Shot MultiBox Detector) |
| **Runtime**           | TensorFlow.js (fully browser-based, no server)                       |
| **Detection Target**  | `person` class                                                       |
| **Engagement Metric** | Detection confidence score (0â€“100%)                                  |
| **Inference loop**    | `requestAnimationFrame` (per-frame, real-time)                       |
| **Noise Analysis**    | `AudioContext` + `AnalyserNode` FFT frequency data                   |

> The AI model runs **entirely on the user's device**. No video, audio, or biometric data is ever transmitted to a remote server.

---

## ğŸš€ Running the Project

### Requirements

- A modern web browser (Google Chrome recommended)
- A local web server such as **Laragon**, XAMPP, or Python's `http.server`
- A webcam and microphone (for camera feed and noise monitoring features)

### Steps

1. Place the project folder in your web server's root directory (e.g., `C:\laragon\www\classroomai`)

2. Start your local server and navigate to:

   ```
   http://classroomai.test       â† Laragon virtual host
   http://localhost/classroomai  â† standard localhost
   ```

3. Open `index.html` to start at the dashboard.

> âš ï¸ **Camera Features Require `localhost` or `HTTPS`** â€” Browsers block camera/microphone access on plain `http://` for security reasons. A local server (Laragon, Live Server, etc.) is sufficient.

---

## ğŸ”¬ Research Conclusions

The project demonstrates that:

1. **AI-based monitoring is feasible in-browser** â€” TensorFlow.js makes it possible to run object detection in real time without dedicated hardware or a server.
2. **Consistency beats manual supervision** â€” an AI system does not tire, lose focus, or make emotional judgments, making it more reliable for long exam sessions.
3. **Engagement can be quantified** â€” by mapping detection confidence and presence data to attention scores, the system creates an objective metric for student engagement.
4. **Scalability is achievable** â€” the same architecture can be extended to multi-camera setups with server-side aggregation for institution-wide analytics.

---

## ğŸ”­ Future Research Directions

- [ ] **Emotion recognition** â€” integrate facial expression analysis to assess student well-being beyond attention
- [ ] **Backend & database integration** â€” store behavioral data over time for longitudinal trend analysis
- [ ] **Multi-camera scaling** â€” support institution-wide monitoring across many rooms simultaneously
- [ ] **Alert system** â€” real-time notifications (email/SMS) to supervisors for detected misconduct
- [ ] **Facial recognition** â€” individual student tracking for granular attendance and engagement data
- [ ] **Edge deployment** â€” run the model on Raspberry Pi or Jetson Nano for offline, low-cost classroom setups
- [ ] **Report generation** â€” export per-session analytics to PDF or CSV for teacher review

---

## ğŸ”’ Privacy & Ethics Statement

This simulation was developed with student privacy as a core consideration:

- âœ… All AI processing runs **locally in the browser** â€” no data leaves the device
- âœ… No student images, video, or biometric data is stored or transmitted
- âœ… Deployed systems would require **informed consent** from students, parents, and institutions
- âœ… Sensitivity settings allow institutions to control detection aggressiveness

Responsible deployment of AI monitoring tools requires appropriate institutional policy, transparency, and regulatory compliance.

---

## ğŸ‘¨â€ğŸ”¬ Project Information

| Field        | Details                                   |
| ------------ | ----------------------------------------- |
| **Event**    | Kenya Science and Engineering Fair (KSEF) |
| **Category** | Computer Science / Engineering            |
| **Year**     | 2025                                      |
| **Type**     | Simulation / Proof-of-Concept             |
| **Level**    | Student Research Project                  |

---

Â© 2026 Classroom AI Analysis â€” Kenya Science and Engineering Fair Submission. All rights reserved.
